# Reproducing results of Super-SloMo  

**Super-SloMo**  
PyTorch implementation of "Super SloMo: High Quality Estimation of Multiple Intermediate Frames for Video Interpolation" by Jiang H., Sun D., Jampani V., Yang M., Learned-Miller E. and Kautz J [Github](https://github.com/avinashpaliwal/Super-SloMo)  

**RIFE**  
PyTorch implementation of "RIFE: Real-Time Intermediate Flow Estimation for Video Frame Interpolation" by Huang, Zhewei and Zhang, Tianyuan and Heng, Wen and Shi, Boxin and Zhou, Shuchang [Github](https://github.com/hzwer/arXiv2020-RIFE)  

**ViT**  
Tensorflow implementation of "Vision Transformer" by Alexey Dosovitskiy*†, Lucas Beyer*, Alexander Kolesnikov*, Dirk Weissenborn*, Xiaohua Zhai*, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit and Neil Houlsby*†. [Github](https://github.com/google-research/vision_transformer)  
(*) equal technical contribution, (†) equal advising.  

---
## Performance indicators
### Super-SloMo


### RIFE

---
## Links  

**Test on Video Frame Interpolation models**  
Google Colab [Super-SloMo](https://drive.google.com/file/d/1ZLRiG26bDlaaMpCwX-esh6EkAr7L47p7/view?usp=sharing)  
Google Colab [RIFE](https://drive.google.com/file/d/1VCstXdI5w3uY3WOFK6KUrEb9wvLgfLh-/view?usp=sharing)  

RIFE takes significantly less time than Super-SloMo.  

**Test on Vision Transformer model**  
Google Colab [ViT](https://drive.google.com/file/d/1Yqu_-YeO0ppbT0j9vlqS1RsrEW5IvTkM/view?usp=sharing)  

requirements.txt file modified 

---
## References
Link to paper [Super-SloMo](https://arxiv.org/abs/1712.00080)   
Link to paper [RIFE](https://arxiv.org/abs/2011.06294)  
Link to paper [ViT](https://arxiv.org/abs/2010.11929)  

